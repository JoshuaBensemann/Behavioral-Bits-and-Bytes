{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision.models import resnet50\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import sys\n",
    "\n",
    "sys.path.append('..')\n",
    "\n",
    "from PAC.train import train_model, training_setup\n",
    "from PAC.eval import evaluate_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_DIR_A = '../data/train_a'\n",
    "INPUT_DIR_TEST = '../data/test_4_a'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Monet', 'Picasso']\n"
     ]
    }
   ],
   "source": [
    "# Define the batch size\n",
    "batch_size = 1\n",
    "\n",
    "# Define the transformation\n",
    "transform = transforms.Compose([\n",
    "    transforms.RandomPerspective(p=1),  # Apply a random perspective transformation\n",
    "    transforms.ToTensor(),  # Convert the image to a tensor\n",
    "    #transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),  # Normalize the image\n",
    "])\n",
    "\n",
    "# Define the dataset\n",
    "dataset = datasets.ImageFolder(INPUT_DIR_A, transform=transform)\n",
    "\n",
    "# Verify the classes\n",
    "train_classes = dataset.classes\n",
    "print(train_classes)\n",
    "\n",
    "dataset = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n",
      "Epoch 1/100: Loss = 13.8860, Accuracy = 42.11%\n",
      "Epoch 2/100: Loss = 13.5207, Accuracy = 42.11%\n",
      "Epoch 3/100: Loss = 13.6548, Accuracy = 47.37%\n",
      "Epoch 4/100: Loss = 12.0410, Accuracy = 68.42%\n",
      "Epoch 5/100: Loss = 11.7357, Accuracy = 73.68%\n",
      "Epoch 6/100: Loss = 12.2040, Accuracy = 68.42%\n",
      "Epoch 7/100: Loss = 11.5631, Accuracy = 68.42%\n",
      "Epoch 8/100: Loss = 11.0437, Accuracy = 78.95%\n",
      "Epoch 9/100: Loss = 11.1960, Accuracy = 73.68%\n",
      "Epoch 10/100: Loss = 10.6578, Accuracy = 78.95%\n",
      "Epoch 11/100: Loss = 10.8485, Accuracy = 78.95%\n",
      "Epoch 12/100: Loss = 10.8695, Accuracy = 84.21%\n",
      "Epoch 13/100: Loss = 10.2752, Accuracy = 84.21%\n",
      "Epoch 14/100: Loss = 9.9629, Accuracy = 94.74%\n"
     ]
    }
   ],
   "source": [
    "# Load the pre-trained ResNet model\n",
    "model = resnet50(weights='ResNet50_Weights.DEFAULT')\n",
    "\n",
    "# Define the number of training epochs\n",
    "num_epochs = 100\n",
    "\n",
    "model, device, criterion, optimizer = training_setup(model, train_classes, lr=0.01)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    accuracy, running_loss = train_model(model, dataset, device, criterion, optimizer)\n",
    "    \n",
    "    # Print the loss and accuracy for each epoch\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}: Loss = {running_loss:.4f}, Accuracy = {accuracy:.2f}%\")\n",
    "    if accuracy > 90:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define transformations for the test data\n",
    "test_transforms = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# Load the test dataset\n",
    "#test_dataset = ImageFolder(INPUT_DIR_TEST, transform=test_transforms)\n",
    "test_dataset = ImageFolder(INPUT_DIR_TEST, transform=test_transforms)\n",
    "eval_classes = test_dataset.classes\n",
    "\n",
    "# Create a DataLoader for the test dataset\n",
    "eval_dataloader = DataLoader(test_dataset, batch_size=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual: Braque, Predicted: Monet 52.68%\n",
      "Actual: Braque, Predicted: Monet 62.55%\n",
      "Actual: Braque, Predicted: Picasso 58.11%\n",
      "Actual: Cezanne, Predicted: Monet 74.03%\n",
      "Actual: Cezanne, Predicted: Monet 64.14%\n",
      "Actual: Cezanne, Predicted: Monet 63.97%\n",
      "Actual: Delacroix, Predicted: Picasso 55.68%\n",
      "Actual: Delacroix, Predicted: Monet 73.05%\n",
      "Actual: Delacroix, Predicted: Monet 81.08%\n",
      "Actual: New_Monet, Predicted: Monet 86.84%\n",
      "Actual: New_Monet, Predicted: Monet 76.3%\n",
      "Actual: New_Monet, Predicted: Monet 88.03%\n",
      "Actual: New_Picasso, Predicted: Picasso 70.21%\n",
      "Actual: New_Picasso, Predicted: Picasso 64.98%\n",
      "Actual: New_Picasso, Predicted: Monet 54.34%\n"
     ]
    }
   ],
   "source": [
    "results = evaluate_model(model, eval_dataloader, device, train_classes, eval_classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
